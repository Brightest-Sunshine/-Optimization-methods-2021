\documentclass{article}
\usepackage[utf8]{inputenc}

\documentclass[a4paper]{article}
\usepackage[12pt]{extsizes}
\usepackage{amsthm, amssymb, amsmath, amsfonts, nccmath, empheq}
\usepackage{float}
\usepackage[hidelinks]{hyperref} 
\usepackage{color,colortbl} 
\renewcommand{\labelenumii}{\Roman{enumii}}
\usepackage[warn]{mathtext}
\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{tocloft}
\linespread{1.5}
\usepackage{indentfirst}
\usepackage{setspace}
%\полуторный интервал
\onehalfspacing


\newtheorem{theorem}{Теорема}
\newtheorem{definition}{Опредление}
\newtheorem{corollary}{Следствие}[theorem]
\newtheorem{lemma}{Лемма}


\newcommand{\RomanNumeralCaps}[1]
    {\MakeUppercase{\romannumeral #1}}

\usepackage{amssymb}

\usepackage{graphicx, float}
\graphicspath{{pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage[left=20mm,right=1cm,
    top=2cm,bottom=20mm,bindingoffset=0cm]{geometry}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}

\addto\captionsrussian{\renewcommand{\contentsname}{СОДЕРЖАНИЕ}}

\usepackage{fancyhdr}
\usepackage[nottoc]{tocbibind}

\fancypagestyle{plain}{%
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyhead[R]{\thepage}
}

\usepackage{blindtext}
\pagestyle{myheadings}
% href
\usepackage{hyperref}
\setcounter{MaxMatrixCols}{20}





\begin{document}
\begin{titlepage}
  \begin{center}
  
     
    \large
    
    Санкт-Петербургский политехнический университет Петра Великого
    
    Институт прикладной математики и механики
    
    \textbf{Высшая школа прикладной математики и вычислительной физики}
    
    \vfill
     
     
    \textsc{\textbf{\Large{Лабораторная работа №5}}}\\[5mm]
     
    {\large \textbf{Тема: <<Решение задач многомерной  минимизации с ограничениями>>}}
    
    \\ по дисциплине\\ <<Методы оптимизаций>>\\

\end{center}

\vfill


\begin{tabular}{l p{140} l}
Выполнили студенты \\группы 3630102/80401   

&  &Мамаева Анастасия Сергеевна\\
&  &Веденичев Дмитрий Александрович\\
&  &Тырыкин Ярослав Алексеевич\\

Руководитель\\Доцент, к.ф.-м.н.& \hspace{0pt} &   Родионова Елена Александровна \\\\
\end{tabular}

\hfill \break
\hfill \break
\begin{center} Санкт-Петербург \\2021 \end{center}
\thispagestyle{empty}
 
\end{titlepage}
\newpage
\begin{center}
    \setcounter{page}{2}
    \tableofcontents  
\end{center}

\newpage
\section{Постановка задачи}
\noindent Пусть имеется задача многомерной минимизации:
$$\varphi_0(x)=x_1^{2}+x_2^{2}+cos(x_1+2x_2)-x_1+2x_2$$
Необходимо:
\begin{enumerate}
    \item Добавить два линейных и одно нелинейное, заданное неквадратичной функцией, ограничения так, чтобы:
    \begin{itemize}
        \item Минимальная точка $x^{*}$ была внутренней точкой множества $\Omega$
        \item Минимальная точка $x^{*}$ была граничной точкой множества $\Omega$
    \end{itemize}
    \item Решить задачу условной минимизации методом отсекающей гиперплоскости
    \item В ходе вычислительного эксперимента нарисовать последовательность точек $x_k$ и множество $\Omega$
\end{enumerate}

\section{Введение ограничений}
\noindent При выполнении лабораторной работы <<Безусловная многомерная минимизация>> была найдена точка оптимума $x^{*}=[0.268;~-1.464]$ при точности вычислений $\varepsilon=10^{-2}$.\\\\
\noindent Введём дополнительные ограничения так, чтобы $x^{*}$ являлась внутренней точкой множества $\Omega_1$:
\begin{equation*}
\Omega_1 = 
    \begin{cases}
    x_1+x_2\le 0.1\\
    -2x_1-x_2\le2\\
    e^{x_1}\le 3
    \end{cases}
\end{equation*}

\noindent Введём дополнительные ограничения так, чтобы $x^{*}$ являлась граничной точкой множества $\Omega_2$:
\begin{equation*}
\Omega_2 = 
    \begin{cases}
    x_1+x_2\le -1.195\\
    -2x_1-x_2\le1.5\\
    e^{x_1}\le 3
    \end{cases}
\end{equation*}

\noindent Построим получившиеся области в программном пакете $Desmos$, и убедимся в достоверности построения областей:
\begin{figure}[H]
\center{\includegraphics[scale=0.9]{First.JPG}}
\label{fig:image}
\caption{Область $\Omega_1$}
\end{figure}

\begin{figure}[H]
\center{\includegraphics[scale=0.85]{Second.JPG}}
\label{fig:image}
\caption{Область $\Omega_2$}
\end{figure}

\noindent В результате построений убедились, что области подобраны верно, согласно изначальным требованиям задачи.
    
\section{Преобразование исходной задачи}
\noindent Необходимо найти
$$\min{\varphi_0(x)}~~\forall x \in \Omega$$
$$где~\varphi_0(x)=c^Tx$$
$$\Omega = \{x \in \mathbb R^{n}|~\varphi(x)\le 0\}$$
$$\varphi(x)~-~непрерывная~выпклая~функция$$
Множество $\Omega$ задаётся только одним ограничением в виде неравенства, функция цели -- линейная. Если множество $\Omega$ задано несколькими неравенствами
$$\varphi_i(x)\le0,~i=\overline{1,~m}$$
где $\varphi_i(x)$ -- непрерывные функции, то полагая $\varphi(x)=\max \limits_{1\le i\le m} \varphi_i(x)$, можем сввести задачу к вышеизложенной.\\\\
\noindent Если функция цели $\varphi_0(x)$ -- нелинейная выпуклая, то, вводя дополнительную переменную $x^{(n+1)}$ и добавляя к $\Omega$ ограничение $$\varphi_{m+1}(x,~x^{(n+1)})=\varphi_0(x)-x^{(n+1)}\le 0$$
можно перейти от исходной задачи к задаче минимизации линейной функции $x^{(n+1)}$ при вышесказанных условиях. Таким образом, без ограничения общности можно рассматривать исходную постановку задачи.
\\\\ Приведём нашу задачу к виду, пригодному для применени алгоритма.
Функция цели $\varphi_0(x)$ нелинейная, введём дополнительное ограничение $\varphi_4(x)$:
$$x_1^{2}+x_2^{2}+cos(x_1+2x_2)-x_1+2x_2-x_3 \le 0$$
тогда задача сводится к тому, чтобы найти минимум линейной функции
$${x_3} \rightarrow min$$
на множествах:
\begin{equation*}
    \Omega_1 = \max \{ 
     x_1+x_2-0.1;~
    -2x_1-x_2 - 2;~
    e^{x_1} - 3 ;~
    x_1^{2}+x_2^{2}+cos(x_1+2x_2)-x_1+2x_2-x_3\} \le 0
\end{equation*}

\begin{equation*}
    \Omega_2 = \max \{ 
     x_1+x_2+1.195;~
    -2x_1-x_2 - 1.5;~
    e^{x_1} - 3 ;~
    x_1^{2}+x_2^{2}+cos(x_1+2x_2)-x_1+2x_2-x_3\} \le 0
\end{equation*}

\section{Построение аппроксимирующего множества $S_0$}
\noindent Исходные множества ограничений $\Omega_1,~\Omega_2 \subset \mathbb R^{3}$ аппроксимируются более простыми. Построим множества $S$ так, чтобы они состояли только из линейны ограничений.
Проще всего описать области прямоугольником. 
Найдём пересечение прямых:
\begin{equation*}
    \begin{cases}
    x_1+x_2=0.1\\
    -2x_1-x_2=2
    \end{cases}
    \rightarrow ~
    \begin{cases}
    x_1=-2.1\\
    x_2=2.2
    \end{cases}
\end{equation*}
Решив $e^{x_1}=3$, получаем $x_1=1.099$. Подставляя в уравнение $-2x_1-x_2=2$, находим $x_2=-4.198$
\begin{figure}[H]
\center{\includegraphics[scale=0.5]{S1.JPG}}
\label{fig:image}
\caption{Область $S_{0_{1}}$}
\end{figure}
\\
\begin{equation*}
    S_{0_{1}}=
    \begin{cases}
    -2.1\le x_1 \le 1.099\\
    -4.198 \le x_2 \le 2.2\\
    -2 \le x_3 \le -1
    \end{cases}
\end{equation*}
 
\noindent Аналогично аппроксмируем вторую область. 
\begin{equation*}
    \begin{cases}
    x_1+x_2=-1.195\\
    -2x_1-x_2=1.5
    \end{cases}
    \rightarrow ~
    \begin{cases}
    x_1=-0.305\\
    x_2=-0.89
    \end{cases}
\end{equation*}
\\
Решив $e^{x_1}=3$, получаем $x_1=1.099$. Подставляя в уравнения $-2x_1-x_2=1.5$, находим $x_2=-3.698$
\begin{figure}[H]
\center{\includegraphics[scale=0.595]{S2.JPG}}
\label{fig:image}
\caption{Область $S_{0_{2}}$}
\end{figure}
\\\\
\begin{equation*}
    S_{0_{2}}=
    \begin{cases}
    -0.305\le x_1 \le 1.099\\
    -3.698 \le x_2 \le -0.89\\
    -2 \le x_3 \le -1
    \end{cases}
\end{equation*}


\section{Применимость метода}
\noindent Для того, чтобы метод отсекающей гиперплоскости сходился необходимо выполнение теоремы:
\begin{theorem}
Пусть $\varphi(x)$ -- непрерывная выпуклая функция, область $\Omega$ компактна, и в каждой точке множества $S_0$ субградиент $a$ функции $\varphi(x)$ ограничен константой, то есть для $\forall x \in S_0$ справедливо неравенство $||a(x)||\le R$. Тогда любая предельная точка $x^{*}~~k=0,1,\dots$ является оптимальной и $\varphi(x_k) \rightarrow 0~~k \rightarrow \infty$.  
\end{theorem}
\\\\
\noindent Проверим выполнение всех требуемых условий для нашей задачи:
\begin{figure}[H]
\center{\includegraphics[scale=0.8]{Natusa_1.pdf}}
\label{fig:image}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[scale=0.8]{Natusa_2.pdf}}
\label{fig:image}
\end{figure}

\section{Описание алгоритмoв}
\subsection{Метод отсекающей гиперплоскости}
\subsubsection{Начальный этап}
\noindent Зададим $\varepsilon>0$ -- параметр окончания вычислений. Будем считать $\Omega=\{x \in R^{n}| \varphi(x) \le 0 \}$ -- непустым компактным множеством. Построим множество $S=\{x|a_i^{T}x-b^{(i)} \le 0, ~i=-l,\dots, -1, 0 \}$, подбирая векторы $a_i$ и числа $b^{(i)}$ так, чтобы $S$ было компактно и $\Omega \subset S$.\\
Положим $S_0=S$. Решим задачу линейного программирования $$\min{c^{T}x},~~\forall x \in S_0$$ Пусть $x_0$ -- решение этой задачи. Положим $k=0$ и перейдём к основному этапу.

\subsubsection{Основной этап}
\noindent Шаг 1:\\
Пусть $S_k$ построено и $x_k$ -- решение задачи линейного программирования $\min{c^{T}x},~~\forall x \in S_k$. Если $x_k \in \Omega$, то $x_k$ -- решение задачи,  следует остановиться. Иначе для $k \ge 1$ проверим условие окончания и в случае невыполнения перейдём к шагу 2.\\\\

\noindent Шаг 2:\\
Построим в точке $x_k$ субградиент $a_{k+1}$ функции $\varphi(x):~ \varphi(x) \ge \varphi(x_k) + a_{k+1}^T (x-x_k)$ для $\forall x \in S_k$. Обозначим $b^{(k+1)}=-\varphi(x_k)+a_{k+1}^T x_k$ и определим область $S_{k+1}:~S_{k+1}=\{x| a_{k+1}^T x - b^{(k+1)} \le 0 \} \cap S_k$. Ясно, что $S_{k+1} \subset S_k$ и для $k\ge 1$
$$S_k=\{x| a_j^{T}x - b^{(j)} \le 0,~j=-l, \dots , -1,0, \dots k \}$$
при использовании для решения симплекс-метода возникает проблема определения начального опорного вектора. Поэтому удобнее перейти к решению двойственной задачи
$$\max{-b^{T}y}$$
$$\sum_{i=-l}^{k} y^{(i)}a_i + c = 0,~~y^{(i)}\ge 0,~~i=\overline{-l,k}$$
Тогда в качестве начального опорного вектора можно взять решение предыдущего итерационного шага, дополнив его компонентной $y^{(k)}=0$.\\\\ 
Заменим $k$ на $k+1$ и перейдём к шагу 1.

\subsubsection{Условие окончания вычислений}
\noindent Если $||x_k-x_{k-1}|| < \varepsilon$, то $x_k$ -- решение задачи.

\subsection{Алгоритм вычисления субградиента}
\noindent На каждой итерации требуется вычислять субградиент функции $\varphi(x)$ в точке $x_k$. Если $\varphi(x)$ -- дифференцируемая функция, то $a_{k+1} = \nabla \varphi(x_k)$. Если же $\varphi(x)=\max \limits_{1\le i \le m} {\varphi_i(x)},~ \varphi_i(x)$ -- дифференцируемые, $1\le i \le m$, то $a_{k+1}$ ищется так:
$$a_{k+1} = \sum_{i \in I(x_k)} \lambda_i \nabla \varphi_i(x_k),~\sum_{i \in I(x_k)} \lambda_i = 1,~~ \lambda_i \ge 0$$
$$I(x_k) = \{ i| \varphi_i(x_k) = \max \limits_{1\le i \le m} \varphi_i(x_k)\}$$
или можно положить $$a_{k+1} = \nabla \varphi_i(x_k)$$
где $i$ -- любой индекс из $I(x_k)$. \\

\noindent Соответсвующая теорема о субградиенте функции $\varphi(x)=\{ \max{\varphi_i(x)} \}, i=\overline{1,m}$ рассматривалась в курсе прошлого семестра.

\section{Результаты решения задачи}
    
    \noindent  При решении задачи многомерной минимизации, обозначенной в начале работы, в случае, когда точное решение $x^*$ является граничной точкой системы ограничений, были полученны следующие результаты:
    
    \begin{equation*}
        x^{*} = [0.267 -1.467 -1.867]
    \end{equation*}
    
    \begin{equation*}
        f(x*) = -1.867
    \end{equation*}
    
\noindent Данные, полученные в результате работы программы:
    
    \begin{itemize}
        \item Оптимум задачи и значение функции в нем:
        \begin{figure}[H]
            \centering
            \includegraphics{Program_Res.JPG}
        \end{figure}
        
        \item Промежуточные вектора $x_k$, получаемые на каждой итерации метода при сужении области поиска решения:
        \begin{figure}[H]
            \centering
            \includegraphics{Iterations_omega_1.JPG}
        \end{figure}
        
        \item Параметры опорных планов, добавляемых к исходной системе ограничений на каждой итерации:
        \begin{figure}[H]
            \centering
            \includegraphics{Hyperplanes_omega_1.JPG}
        \end{figure}
    \end{itemize}
    
\noindent При минимизации той же целевой функции, но ограничниях, заданных таким образом, что точное решение является граничной точкой системы ограничений, были получены следующие данные:
        
    \begin{equation*}
        x^{*} = [0.266 -1.469 -1.867]
    \end{equation*}
    
    \begin{equation*}
        f(x*) = -1.867
    \end{equation*}
    
    \begin{itemize}
        \item Оптимум задачи и значение функции в нем:
        \begin{figure}[H]
            \centering
            \includegraphics{Result_omega_2.JPG}
        \end{figure}
        
        \item Промежуточные вектора $x_k$, получаемые на каждой итерации метода при сужении области поиска решения:
        \begin{figure}[H]
            \centering
            \includegraphics{Itarations_omega_2.JPG}
        \end{figure}
        
        \item Параметры опорных планов, добавляемых к исходной системе ограничений на каждой итерации:
        
        \begin{figure}[H]
            \centering
            \includegraphics{Hyperplanes_omega_2.JPG}
        \end{figure}
    \end{itemize}
    
\noindent Точность проведения расчетов в обоих опытах берется равной $\varepsilon = 0.001$ \\

    \noindent Графическая илюстрация работы метода отсекающих гиперплоскостей приведодится ниже на примере решения задачи с системой ограничений $\omega_1$:
    
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.48]{Illustration_of_algo.jpeg}
    \end{figure}

\section{Оценка достоверности полученных результатов}

\begin{figure}[H]
\center{\includegraphics[scale=0.76]{1.pdf}}
\label{fig:image}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[scale=0.85]{2.pdf}}
\label{fig:image}
\end{figure}

\section{Программная реализация}
\noindent В процессе реализации алгоритмов использовался язык программирования Python3.6. Для проверки полученных решений пользовались пакетом MATLAB2020b.
\\\\
\noindent Исходный код находится в системе контроля версий GitHub 
\\
https://github.com/Brightest-Sunshine/Optimization-methods-2021

\section{Выводы}
\begin{enumerate}
 \item Скорость сходимости метода отсекающей гиперплоскости невысока. Она меньше геометрической.
 \item Достоинство метода заключается в том, что решаемая на каждом итерационном шаге вспомагательная задача относится к задачам линейного программирования, метода решения которых хорошо разработаны. При переходе к двойственной постановке легко строится начальное приближение для двойственной задачи.
\end{enumerate}

\section{Ответы на дополнительные вопросы}

    \subsection{Метод аппроксимации множества ограничений задачи}
        
        \noindent Так как по условию задачи множество ограничений задано в виде системы нелинейных уравнений, перед применением алгоритма возникает проблема приведения ограничений задачи к виду, удобному для вычислений. Аппроксимировать множество, ограниченного неравенствами с нелинейными функциями, можно при помощи выпуклого полиэдра, который можно построить следующим образом:
        
        \begin{itemize}
            \item Выбираем $i-$ую компоненту пространства $R^n$ и ищем ее наибольшее и наименьшее значение среди всех точек множества ограничений методом перебора (то есть, строим диаметр множества по данной компоненте).
            \item Добавляем два неравенства, ограничивающих значения данной компоненты, в систему, задающую полиэдр.
        \end{itemize}
        
        \noindent Применив данные шаги к каждой из компонент простанства, получим систему линейных ограничений, задающих полиэдр со сторонами - диаметрами исходного аппроксимированного множества.

   \subsection{Экспериментальные оценки сходимости метода}
       \noindent  В качестве дополнительной иллюстрации работы метода отсекающей гиперплоскости и демострации сходимости минимизирующей последовательности приводится следующий фрагмент программного вывода:
        
        \begin{figure}[H]
            \centering
            \includegraphics{Subtraction_norm.JPG}
        \end{figure}
        
        \noindent Решение строилось для задачи минимизации с областью допустимых значений, при которой решение задачи лежит на границе области. Точность вычислений $\varepsilon$ бралась равной $0.01$.\\
        
        \noindent Кроме того, для демонстрации сходимости метода отсекающей гиперплоскости для разных $\varepsilon$ была построена следующая зависимость фактической точности получения результата от требуемой, представленная на следующей иллюстрации:
        
        \begin{figure}[H]
            \centering
            \includegraphics{Calc_accuracy_plot.png}
        \end{figure}
        
        \noindent Для построения зависимости бралась задача минимизации с ограниченями, при которых решение находится на границе области допустимых значений. Точным решением на каждой итерации принималось решение задачи минимизации, полученное методом optimize из библиотеки SciPy - вспомогательного пакета математических функций, реализованного на языке программирования Python. Как видно на графике, точность изменялась в пределах от $0.1$ до $10^{-6}$.
    
    \subsection{Обоснование отклонения нормы разности от нормального процесса сходимости метода}
    
    \noindent Приведем для примера результаты решения задачи, приведенной в пункте 2, с решением, лежащим на границе области ограничений, и точностью $\varepsilon = 0.001$:
    
    \begin{figure}[H]
        \centering
        \includegraphics{Subtraction_norm_2.JPG}

    \end{figure}
    
    \noindent Кроме того, построим график иллюстрации нормы разности двух соседних векторов $x_k$ на каждой итерации:
    
    \begin{figure}[H]
        \centering
        \includegraphics[scale =0.52]{Iterations_sequence.jpeg}
    \end{figure}
    
    \begin{definition}
    Последовательность $\{x_k\}$ называется сходящейся, если $\forall \varepsilon>0~~\exists N>0:~\forall k, m > N \Rightarrow ||x_k-x_m||<\varepsilon$ 
    \end{definition}
    
    \noindent Как видно, норма разности совершает несколько скачков, но в целом сходится к решению задачи с требуемой точностью. Отталкиваясь от определения выше, видим что в данном случае $N= 15$. Это значит, что после того как номера индексов будут превоcходить $N=15$, скачки прекратятся. Наличие же скачков связано с применением симплекс-метода на каждой итерации метода отсекающих гиперплоскостей. Из-за того, что симплекс имеет вытянутую форму, алгоритм берет слишком большой шаг, вследствие чего метод на данной итерации проходит дальше искомого решения, и появляется небольшое расхождение по норме.

\begin{thebibliography}{9}
\bibitem{book1} Пшеничный Б. Н., Данилин Ю. М. Численные методы в экстремальных задачах. М.: Наука, 1975. 319с.
\bibitem{book2} Численные методы условной минимизации/ Под ред. Ф. Гилл, У. Мюррей. М.: Мир, 1977. 290с.
\bibitem{book3} Лесин В. В., Лисовец Ю. П. Основы методов оптимизации: Учебное пособие. 3-е изд., испр, -- СПб.: Издательство <<Лань>>, 2011. -- 352с.
\end{thebibliography}

\end{document}
